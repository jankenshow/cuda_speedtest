{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import cuda\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 2070 SUPER'                              [SUPPORTED]\n",
      "                      Compute Capability: 7.5\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-d76dbc1d-cbf5-d7ba-7ff2-b858d30bc8f2\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.cuda.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [256, 1024, 4096]\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numba (CUDA)　での行列積速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = nb.cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensho/.pyenv/versions/3.8.12/lib/python3.8/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (64) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home/kensho/.pyenv/versions/3.8.12/lib/python3.8/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (64) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列サイズ = 256\n",
      "処理時間 : memcpy = 0.006049704551696777\n",
      "処理時間 : kernel = 0.0007893562316894532\n",
      "処理時間 : total  = 0.006937479972839356\n",
      "行列サイズ = 1024\n",
      "処理時間 : memcpy = 0.0021799802780151367\n",
      "処理時間 : kernel = 0.03197135925292969\n",
      "処理時間 : total  = 0.034659957885742186\n",
      "行列サイズ = 4096\n",
      "処理時間 : memcpy = 0.021010565757751464\n",
      "処理時間 : kernel = 1.7810150146484376\n",
      "処理時間 : total  = 1.812699317932129\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    x = np.random.randn(size, size).astype(np.float32)\n",
    "    y = np.random.randn(size, size).astype(np.float32)\n",
    "    out = np.zeros((size, size)).astype(np.float32)\n",
    "\n",
    "    threads = (TPB, TPB)\n",
    "    blocks = (math.ceil(size / threads[0]), math.ceil(size / threads[1]))\n",
    "\n",
    "    d_sec_memcpy = 0\n",
    "    d_sec_kernel = 0\n",
    "    d_sec_total = 0\n",
    "    for i in range(iterations+1):\n",
    "        start = time.time()\n",
    "\n",
    "        d_x = nb.cuda.to_device(x)\n",
    "        d_y = nb.cuda.to_device(y)\n",
    "        d_o = nb.cuda.to_device(out)\n",
    "\n",
    "        # 時間計測 (memcpy)\n",
    "        nb.cuda.synchronize()\n",
    "        memcpy_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_memcpy += (memcpy_end - start)\n",
    "\n",
    "\n",
    "        matmul[blocks, threads](d_x, d_y, d_o)\n",
    "\n",
    "        # 時間計測 (kernel)\n",
    "        nb.cuda.synchronize()\n",
    "        kernel_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_kernel += (kernel_end - memcpy_end)\n",
    "\n",
    "\n",
    "        out = d_o.copy_to_host()\n",
    "\n",
    "        # 時間計測 (total)\n",
    "        nb.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_total += (end - start)\n",
    "\n",
    "\n",
    "    d_sec_memcpy /= iterations\n",
    "    d_sec_kernel /= iterations\n",
    "    d_sec_total /= iterations\n",
    "    print(f\"行列サイズ = {size}\")\n",
    "    print(f\"処理時間 : memcpy = {d_sec_memcpy}\")\n",
    "    print(f\"処理時間 : kernel = {d_sec_kernel}\")\n",
    "    print(f\"処理時間 : total  = {d_sec_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = nb.cuda.shared.array(shape=(TPB, TPB), dtype=nb.float32)\n",
    "    sB = nb.cuda.shared.array(shape=(TPB, TPB), dtype=nb.float32)\n",
    "\n",
    "    x, y = nb.cuda.grid(2)\n",
    "\n",
    "    tx = nb.cuda.threadIdx.x\n",
    "    ty = nb.cuda.threadIdx.y\n",
    "    bpg = nb.cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        nb.cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        nb.cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kensho/.pyenv/versions/3.8.12/lib/python3.8/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (64) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列サイズ = 256\n",
      "処理時間 : memcpy = 0.0008071184158325196\n",
      "処理時間 : kernel = 0.000883793830871582\n",
      "処理時間 : total  = 0.0017897844314575194\n",
      "行列サイズ = 1024\n",
      "処理時間 : memcpy = 0.0021622419357299806\n",
      "処理時間 : kernel = 0.03261787891387939\n",
      "処理時間 : total  = 0.035291433334350586\n",
      "行列サイズ = 4096\n",
      "処理時間 : memcpy = 0.020765161514282225\n",
      "処理時間 : kernel = 1.9950968503952027\n",
      "処理時間 : total  = 2.026572012901306\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    x = np.random.randn(size, size).astype(np.float32)\n",
    "    y = np.random.randn(size, size).astype(np.float32)\n",
    "    out = np.zeros((size, size)).astype(np.float32)\n",
    "\n",
    "    threads = (TPB, TPB)\n",
    "    blocks = (math.ceil(size / threads[0]), math.ceil(size / threads[1]))\n",
    "\n",
    "    d_sec_memcpy = 0\n",
    "    d_sec_kernel = 0\n",
    "    d_sec_total = 0\n",
    "    for i in range(iterations+1):\n",
    "        start = time.time()\n",
    "\n",
    "        d_x = nb.cuda.to_device(x)\n",
    "        d_y = nb.cuda.to_device(y)\n",
    "        d_o = nb.cuda.to_device(out)\n",
    "\n",
    "        # 時間計測 (memcpy)\n",
    "        nb.cuda.synchronize()\n",
    "        memcpy_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_memcpy += (memcpy_end - start)\n",
    "\n",
    "\n",
    "        fast_matmul[blocks, threads](d_x, d_y, d_o)\n",
    "\n",
    "        # 時間計測 (kernel)\n",
    "        nb.cuda.synchronize()\n",
    "        kernel_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_kernel += (kernel_end - memcpy_end)\n",
    "\n",
    "\n",
    "        out = d_o.copy_to_host()\n",
    "\n",
    "        # 時間計測 (total)\n",
    "        nb.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_total += (end - start)\n",
    "\n",
    "\n",
    "    d_sec_memcpy /= iterations\n",
    "    d_sec_kernel /= iterations\n",
    "    d_sec_total /= iterations\n",
    "    print(f\"行列サイズ = {size}\")\n",
    "    print(f\"処理時間 : memcpy = {d_sec_memcpy}\")\n",
    "    print(f\"処理時間 : kernel = {d_sec_kernel}\")\n",
    "    print(f\"処理時間 : total  = {d_sec_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numba ブロックあたりのスレッド数を変えた場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = nb.cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = nb.cuda.shared.array(shape=(TPB, TPB), dtype=nb.float32)\n",
    "    sB = nb.cuda.shared.array(shape=(TPB, TPB), dtype=nb.float32)\n",
    "\n",
    "    x, y = nb.cuda.grid(2)\n",
    "\n",
    "    tx = nb.cuda.threadIdx.x\n",
    "    ty = nb.cuda.threadIdx.y\n",
    "    bpg = nb.cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        nb.cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        nb.cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列サイズ = 256\n",
      "処理時間 : memcpy = 0.005876660346984863\n",
      "処理時間 : kernel = 0.00043044090270996096\n",
      "処理時間 : total  = 0.006404805183410645\n",
      "行列サイズ = 1024\n",
      "処理時間 : memcpy = 0.0021755218505859373\n",
      "処理時間 : kernel = 0.0193359375\n",
      "処理時間 : total  = 0.022016334533691406\n",
      "行列サイズ = 4096\n",
      "処理時間 : memcpy = 0.021129441261291505\n",
      "処理時間 : kernel = 0.9916394948959351\n",
      "処理時間 : total  = 1.0234895944595337\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    x = np.random.randn(size, size).astype(np.float32)\n",
    "    y = np.random.randn(size, size).astype(np.float32)\n",
    "    out = np.zeros((size, size)).astype(np.float32)\n",
    "\n",
    "    threads = (TPB, TPB, 1)\n",
    "    blocks = (math.ceil(size / threads[0]), math.ceil(size / threads[1]), 1)\n",
    "\n",
    "    d_sec_memcpy = 0\n",
    "    d_sec_kernel = 0\n",
    "    d_sec_total = 0\n",
    "    for i in range(iterations+1):\n",
    "        start = time.time()\n",
    "\n",
    "        d_x = nb.cuda.to_device(x)\n",
    "        d_y = nb.cuda.to_device(y)\n",
    "        d_o = nb.cuda.to_device(out)\n",
    "\n",
    "        # 時間計測 (memcpy)\n",
    "        nb.cuda.synchronize()\n",
    "        memcpy_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_memcpy += (memcpy_end - start)\n",
    "\n",
    "\n",
    "        matmul[blocks, threads](d_x, d_y, d_o)\n",
    "\n",
    "        # 時間計測 (kernel)\n",
    "        nb.cuda.synchronize()\n",
    "        kernel_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_kernel += (kernel_end - memcpy_end)\n",
    "\n",
    "\n",
    "        out = d_o.copy_to_host()\n",
    "\n",
    "        # 時間計測 (total)\n",
    "        nb.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_total += (end - start)\n",
    "\n",
    "\n",
    "    d_sec_memcpy /= iterations\n",
    "    d_sec_kernel /= iterations\n",
    "    d_sec_total /= iterations\n",
    "    print(f\"行列サイズ = {size}\")\n",
    "    print(f\"処理時間 : memcpy = {d_sec_memcpy}\")\n",
    "    print(f\"処理時間 : kernel = {d_sec_kernel}\")\n",
    "    print(f\"処理時間 : total  = {d_sec_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列サイズ = 256\n",
      "処理時間 : memcpy = 0.000793290138244629\n",
      "処理時間 : kernel = 0.00037403106689453124\n",
      "処理時間 : total  = 0.0012653589248657227\n",
      "行列サイズ = 1024\n",
      "処理時間 : memcpy = 0.0021138906478881834\n",
      "処理時間 : kernel = 0.015891551971435547\n",
      "処理時間 : total  = 0.01850621700286865\n",
      "行列サイズ = 4096\n",
      "処理時間 : memcpy = 0.02103612422943115\n",
      "処理時間 : kernel = 1.0008277654647828\n",
      "処理時間 : total  = 1.0325467109680175\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    x = np.random.randn(size, size).astype(np.float32)\n",
    "    y = np.random.randn(size, size).astype(np.float32)\n",
    "    out = np.zeros((size, size)).astype(np.float32)\n",
    "\n",
    "    threads = (TPB, TPB)\n",
    "    blocks = (math.ceil(size / threads[0]), math.ceil(size / threads[1]))\n",
    "\n",
    "    d_sec_memcpy = 0\n",
    "    d_sec_kernel = 0\n",
    "    d_sec_total = 0\n",
    "    for i in range(iterations+1):\n",
    "        start = time.time()\n",
    "\n",
    "        d_x = nb.cuda.to_device(x)\n",
    "        d_y = nb.cuda.to_device(y)\n",
    "        d_o = nb.cuda.to_device(out)\n",
    "\n",
    "        # 時間計測 (memcpy)\n",
    "        nb.cuda.synchronize()\n",
    "        memcpy_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_memcpy += (memcpy_end - start)\n",
    "\n",
    "\n",
    "        fast_matmul[blocks, threads](d_x, d_y, d_o)\n",
    "\n",
    "        # 時間計測 (kernel)\n",
    "        nb.cuda.synchronize()\n",
    "        kernel_end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_kernel += (kernel_end - memcpy_end)\n",
    "\n",
    "\n",
    "        out = d_o.copy_to_host()\n",
    "\n",
    "        # 時間計測 (total)\n",
    "        nb.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        if i != 0:\n",
    "            d_sec_total += (end - start)\n",
    "\n",
    "\n",
    "    d_sec_memcpy /= iterations\n",
    "    d_sec_kernel /= iterations\n",
    "    d_sec_total /= iterations\n",
    "    print(f\"行列サイズ = {size}\")\n",
    "    print(f\"処理時間 : memcpy = {d_sec_memcpy}\")\n",
    "    print(f\"処理時間 : kernel = {d_sec_kernel}\")\n",
    "    print(f\"処理時間 : total  = {d_sec_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorchでの行列積速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列サイズ = 256\n",
      "処理時間 : memcpy = 9.646415710449219e-05\n",
      "処理時間 : kernel = 3.139972686767578e-05\n",
      "処理時間 : total  = 0.00019218921661376954\n",
      "行列サイズ = 1024\n",
      "処理時間 : memcpy = 0.0008085727691650391\n",
      "処理時間 : kernel = 0.00033447742462158205\n",
      "処理時間 : total  = 0.002263975143432617\n",
      "行列サイズ = 4096\n",
      "処理時間 : memcpy = 0.011610937118530274\n",
      "処理時間 : kernel = 0.015471220016479492\n",
      "処理時間 : total  = 0.04687211513519287\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    x = torch.randn((size, size), dtype=torch.float32, requires_grad=False)\n",
    "    y = torch.randn((size, size), dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "    d_sec_memcpy = 0\n",
    "    d_sec_kernel = 0\n",
    "    d_sec_total = 0\n",
    "    for i in range(iterations+1):\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "\n",
    "            d_x = x.to(device)\n",
    "            d_y = y.to(device)\n",
    "\n",
    "            # 時間計測 (memcpy)\n",
    "            torch.cuda.synchronize()\n",
    "            memcpy_end = time.time()\n",
    "            if i != 0:\n",
    "                d_sec_memcpy += (memcpy_end - start)\n",
    "\n",
    "\n",
    "            d_out = torch.matmul(d_x, d_y)\n",
    "\n",
    "            # 時間計測 (kernel)\n",
    "            torch.cuda.synchronize()\n",
    "            kernel_end = time.time()\n",
    "            if i != 0:\n",
    "                d_sec_kernel += (kernel_end - memcpy_end)\n",
    "\n",
    "\n",
    "            out = d_out.to(\"cpu\")\n",
    "\n",
    "            # 時間計測 (total)\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if i != 0:\n",
    "                d_sec_total += (end - start)\n",
    "\n",
    "\n",
    "    d_sec_memcpy /= iterations\n",
    "    d_sec_kernel /= iterations\n",
    "    d_sec_total /= iterations\n",
    "    print(f\"行列サイズ = {size}\")\n",
    "    print(f\"処理時間 : memcpy = {d_sec_memcpy}\")\n",
    "    print(f\"処理時間 : kernel = {d_sec_kernel}\")\n",
    "    print(f\"処理時間 : total  = {d_sec_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列サイズ = 256\n",
      "処理時間 : memcpy = 9.932518005371094e-05\n",
      "処理時間 : kernel = 3.235340118408203e-05\n",
      "処理時間 : total  = 0.00019829273223876954\n",
      "行列サイズ = 1024\n",
      "処理時間 : memcpy = 0.0009094476699829102\n",
      "処理時間 : kernel = 0.0003421783447265625\n",
      "処理時間 : total  = 0.002171969413757324\n",
      "行列サイズ = 4096\n",
      "処理時間 : memcpy = 0.011600351333618164\n",
      "処理時間 : kernel = 0.015173029899597169\n",
      "処理時間 : total  = 0.046537160873413086\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    x = torch.randn((size, size), dtype=torch.float32, requires_grad=False)\n",
    "    y = torch.randn((size, size), dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "    d_sec_memcpy = 0\n",
    "    d_sec_kernel = 0\n",
    "    d_sec_total = 0\n",
    "    for i in range(iterations+1):\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "\n",
    "            d_x = x.to(device)\n",
    "            d_y = y.to(device)\n",
    "\n",
    "            # 時間計測 (memcpy)\n",
    "            torch.cuda.synchronize()\n",
    "            memcpy_end = time.time()\n",
    "            if i != 0:\n",
    "                d_sec_memcpy += (memcpy_end - start)\n",
    "\n",
    "\n",
    "            d_out = torch.matmul(d_x, d_y)\n",
    "\n",
    "            # 時間計測 (kernel)\n",
    "            torch.cuda.synchronize()\n",
    "            kernel_end = time.time()\n",
    "            if i != 0:\n",
    "                d_sec_kernel += (kernel_end - memcpy_end)\n",
    "\n",
    "\n",
    "            out = d_out.to(\"cpu\")\n",
    "\n",
    "            # 時間計測 (total)\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if i != 0:\n",
    "                d_sec_total += (end - start)\n",
    "\n",
    "\n",
    "    d_sec_memcpy /= iterations\n",
    "    d_sec_kernel /= iterations\n",
    "    d_sec_total /= iterations\n",
    "    print(f\"行列サイズ = {size}\")\n",
    "    print(f\"処理時間 : memcpy = {d_sec_memcpy}\")\n",
    "    print(f\"処理時間 : kernel = {d_sec_kernel}\")\n",
    "    print(f\"処理時間 : total  = {d_sec_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5df1eb4a1e6542f387629c32d5de3c12cfb42a69b08ccd1dde42d349eb96200c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
